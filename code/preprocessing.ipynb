{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f6213cf",
   "metadata": {},
   "source": [
    "# 1. IMPORTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cee7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from fast_ml.feature_selection import get_duplicate_features\n",
    "from fast_ml.feature_selection import get_constant_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba29b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dataset\n",
    "df = pd.read_csv(\"../data/source/dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8c0d90",
   "metadata": {},
   "source": [
    "# 2. SPLITTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdc7bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data on which we base\n",
    "X = df.drop(columns=['target'])\n",
    "\n",
    "# data which we predict\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ff3d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# getting test and validation sets\n",
    "X_test, X_val, y_test, y_val = train_test_split(\n",
    "    X_test, y_test, stratify=y_test, test_size=0.3, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f5e11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking shapes of X's\n",
    "print(X.shape, X_train.shape, X_test.shape, X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b4ea21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking shapes of y's\n",
    "print(y.shape, y_train.shape, y_test.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f54ee0",
   "metadata": {},
   "source": [
    "# EXPORTING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cd1d39",
   "metadata": {},
   "source": [
    "# exporting data\n",
    "relative_path = \"../data/validation\"\n",
    "\n",
    "if not os.path.exists(relative_path):\n",
    "    os.makedirs(relative_path)\n",
    "\n",
    "X_train.to_csv(relative_path + '/train_X.csv', encoding='utf-8')\n",
    "X_test.to_csv(relative_path + '/test_X.csv', encoding='utf-8')\n",
    "X_val.to_csv(relative_path + '/val_X.csv', encoding='utf-8')\n",
    "\n",
    "y_train.to_csv(relative_path + '/train_y.csv', encoding='utf-8')\n",
    "y_test.to_csv(relative_path + '/test_y.csv', encoding='utf-8')\n",
    "y_val.to_csv(relative_path + '/val_y.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ae7752",
   "metadata": {},
   "source": [
    "# 3. DATASET INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d77fde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# first five rows\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266ec0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63db5579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd04d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# info\n",
    "X_train.info(verbose=True, show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb4abb0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# description\n",
    "X_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10210ae",
   "metadata": {},
   "source": [
    "# 4. TRANSFORMATIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674d76a7",
   "metadata": {},
   "source": [
    "## 4.11 NAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dfe920f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nan_handler(df):\n",
    "    # medians per column\n",
    "    medians_train = {}\n",
    "    \n",
    "    # iterate over every column\n",
    "    for column in df.columns:\n",
    "        # calculate median for given column\n",
    "        medians_train[column] = df[column].median()\n",
    "        \n",
    "        # replace NAs with median\n",
    "        df[column].fillna(medians_train[column], inplace=True)\n",
    "        \n",
    "    print(\"NAs handled\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e170c6d",
   "metadata": {},
   "source": [
    "## 4.2. OUTLIERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35deeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import zscore\n",
    "\n",
    "def outliers_handler(df):\n",
    "    # calculate z-scores for each column\n",
    "    z_scores = np.abs(zscore(df))\n",
    "    \n",
    "    # set a threshold for the z-score values\n",
    "    threshold = 2.5\n",
    "    \n",
    "    # define the means_train dictionary\n",
    "    means_train = {}\n",
    "\n",
    "    # loop over each column in X_train\n",
    "    for column in df.columns:\n",
    "        # ientify the rows where the z-score exceeds the threshold  \n",
    "        outliers = z_scores[column] > threshold\n",
    "\n",
    "        # calculate the mean of the column excluding outliers\n",
    "        means_train[column] = np.nanmean(df[column][~outliers])\n",
    "\n",
    "        # replace values that exceed the threshold\n",
    "        if outliers.any():\n",
    "            # values in current columns with outliers\n",
    "            values = df[column].values\n",
    "            \n",
    "            # mean with no outliers\n",
    "            mean = means_train[column]\n",
    "            \n",
    "            # True is written where outlier is\n",
    "            mask = outliers\n",
    "            \n",
    "            # iterate through every outlier in column\n",
    "            for i in np.where(mask)[0]:\n",
    "                if values[i] > mean:\n",
    "                    # find last value greater than mean and within 2.5 std\n",
    "                    replacement_candidates = values[(values > mean) & ~outliers]\n",
    "                    if len(replacement_candidates) > 0:\n",
    "                        replacement = sorted(replacement_candidates)[-1]\n",
    "                    else:\n",
    "                        replacement = mean\n",
    "                else:\n",
    "                    # find last value less than mean and within 2.5 std\n",
    "                    replacement_candidates = values[(values < mean) & ~outliers]\n",
    "                    if len(replacement_candidates) > 0:\n",
    "                        replacement = sorted(replacement_candidates)[0]\n",
    "                    else:\n",
    "                        replacement = mean\n",
    "                df.iloc[i, df.columns.get_loc(column)] = replacement\n",
    "                \n",
    "    print(\"outliers handled\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaab7171",
   "metadata": {},
   "source": [
    "## 4.3. STANDARIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc66febf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scaler imported from sklearn instead of self written code\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "scaler.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1416ef72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standarization_handler(df):\n",
    "    scaler.transform(df)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8371a31d",
   "metadata": {},
   "source": [
    "# 5. FEATURE NUMBER REDUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbeab353",
   "metadata": {},
   "source": [
    "## 5.1. DUPLICATES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f27ded2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_duplicate_features(df):\n",
    "    # retrieve duplicate features object\n",
    "    duplicate_features = get_duplicate_features(df)\n",
    "    \n",
    "    # retrieve names of duplicate features\n",
    "    duplicate_features = duplicate_features[duplicate_features['Desc'] == 'Duplicate Values']['feature2'].tolist()\n",
    "    \n",
    "    # remove duplicates\n",
    "    df.drop(columns = duplicate_features, inplace=True)\n",
    "    \n",
    "    print(\"duplicate features dropped\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61895b24",
   "metadata": {},
   "source": [
    "## 5.2. CONSTANTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e3d58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_constant_features(df):\n",
    "    # retrieve constant features object\n",
    "    constant_features = get_constant_features(df)\n",
    "    \n",
    "    # retrieve names of constant features\n",
    "    constant_features = constant_features[constant_features['Perc'] > 98]['Var'].tolist()\n",
    "    \n",
    "    # remove constant features\n",
    "    df.drop(columns = constant_features, inplace=True)\n",
    "    \n",
    "    print(\"constant features dropped\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a92f8a2",
   "metadata": {},
   "source": [
    "## 5.3. CORRELATED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d9be25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_correlated_features(df):\n",
    "    # calculate correlation\n",
    "    corr = df.corr(method=\"spearman\").abs()\n",
    "    \n",
    "    # retrieve correlation data\n",
    "    upper_triangle = corr.where(np.triu(np.ones(corr.shape), k=1).astype(bool))\n",
    "    \n",
    "    # retrieve highly correlated features' names\n",
    "    corr_features = []\n",
    "    for col in upper_triangle:\n",
    "        if any(upper_triangle[col] > 0.8): \n",
    "            corr_features.append(col)\n",
    "\n",
    "    # remove correlated features\n",
    "    corr_features = pd.Series(corr_features)\n",
    "    df.drop(columns = corr_features, inplace=True)\n",
    "    \n",
    "    print(\"correlated features dropped\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8397932",
   "metadata": {},
   "source": [
    "# 6. MODELS "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ddb623",
   "metadata": {},
   "source": [
    "## 6.1 Test data preparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c9188b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(df, consistent_cols = []):\n",
    "    if len(consistent_cols)==0:\n",
    "        drop_duplicate_features(df)\n",
    "        print(\"duplicated featured deleted\")\n",
    "        drop_constant_features(df)\n",
    "        print(\"constant features dropped\")\n",
    "        drop_correlated_features(df)\n",
    "        print(\"correlated features deleted\")\n",
    "    else:\n",
    "        to_drop = filter(lambda i: i not in consistent_cols, df.columns)\n",
    "        df.drop(columns = list(to_drop), inplace=True)\n",
    "        print(\"columns consistent\")\n",
    "    outliers_handler(df)\n",
    "    print(\"outliers removed\")\n",
    "    nan_handler(df)\n",
    "    print(\"nan removed\")\n",
    "    standarization_handler(df)\n",
    "    print(\"dataset standaraized\")\n",
    "    nan_removing(df)\n",
    "\n",
    "prepare_dataset(X_test, X_train.columns)\n",
    "print(X_test.shape, \"TEST dataset\")\n",
    "print(X_train.shape, \"TRAIN dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c36601",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train and test shape are the same\n",
    "print(X_test.columns)\n",
    "print(X_train.columns)\n",
    "to_drop = filter(lambda i: i not in list(X_train.columns), list(X_test.columns))\n",
    "X_test.drop(columns = list(to_drop), inplace=True)\n",
    "print(list(to_drop))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d617c8ac",
   "metadata": {},
   "source": [
    "## 6.2 Evaluating Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3f09ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing ROC-AUC score to valuate models\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# importing ROC curve to visualize ROC curve\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# matplotlib to draw plots of ROC-AUC curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# confusion matrix to show TP, TN, FP, FN\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# classification report to describe model accuracy\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2c6ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_evaluation(model, X_df, y_df):\n",
    "    y_pred_proba = model.predict_proba(X_df)\n",
    "    y_pred = model.predict(X_df)\n",
    "    # roc curve for models\n",
    "    fpr_model, tpr_model, thresh_model = roc_curve(y_test, y_pred_proba[:,1], pos_label=1)\n",
    "\n",
    "    # roc curve for tpr = fpr \n",
    "    random_probs = [0 for i in range(len(y_df))]\n",
    "    p_fpr, p_tpr, _ = roc_curve(y_df, random_probs, pos_label=1)\n",
    "\n",
    "    plt.style.use('seaborn')\n",
    "\n",
    "    # plot roc curves\n",
    "    plt.plot(fpr_model, tpr_model, linestyle='--',color='orange', label='Random Forest')\n",
    "    plt.plot(p_fpr, p_tpr, linestyle='--', color='blue')\n",
    "    # title\n",
    "    plt.title('ROC curve')\n",
    "    # x label\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    # y label\n",
    "    plt.ylabel('True Positive rate')\n",
    "\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig('ROC',dpi=300)\n",
    "    plt.show();\n",
    "    \n",
    "    # auc scores\n",
    "    auc_score_model = roc_auc_score(y_df, y_pred_proba[:,1])\n",
    "\n",
    "    print(\"Classification report: \", \"\\n\" , classification_report(y_df, y_pred))\n",
    "    print(\"Random Forest Score: \", model.score(X_df,y_df))\n",
    "    print(\"AUC score: \", auc_score_model)\n",
    "    \n",
    "    ConfusionMatrixDisplay.from_estimator(model, X_df, y_df)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f84441",
   "metadata": {},
   "source": [
    "## 6.3 K Neighbors model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a078358",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "KN_model = KNeighborsClassifier(n_neighbors=4)\n",
    "KN_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2816c262",
   "metadata": {},
   "source": [
    "### EVALUATION OF KNEIGHBORS MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022a1677",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model_evaluation(KN_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6286d70d",
   "metadata": {},
   "source": [
    "## 6.4 Logistic Regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0834f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LR_model = LogisticRegression()\n",
    "LR_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bddb6c",
   "metadata": {},
   "source": [
    "### EVALUATION OF LOGISTIC REGRESSION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833aca31",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluation(LR_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b572c319",
   "metadata": {},
   "source": [
    "## 6.5 Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c185353b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc60c2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=100, n_jobs=2)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2eaaf2",
   "metadata": {},
   "source": [
    "### EVALUATION OF RANDOM FOREST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161c45ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluation(rf_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "592bc7dd",
   "metadata": {},
   "source": [
    "### VERIFYING FEATURE IMPORTANCE IN RANDOM FOREST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a40b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importances and sort them in descending order\n",
    "importances = rf_model.feature_importances_\n",
    "sorted_indices = importances.argsort()[::-1]\n",
    "columns = X_test.columns\n",
    "\n",
    "# Identify non-predictive columns\n",
    "non_predictive_cols = []\n",
    "for i in sorted_indices:\n",
    "    if importances[i] < 0.05:\n",
    "        non_predictive_cols.append(columns[i])\n",
    "\n",
    "# Remove non-predictive columns\n",
    "reduced_X = pd.DataFrame(X_test).drop(non_predictive_cols, axis=1)\n",
    "\n",
    "# Train a new random forest classifier on the reduced dataset\n",
    "rf_model_reduced = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model_reduced.fit(reduced_X, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f51829",
   "metadata": {},
   "source": [
    "### 2ND EVALUATION OF RANDOM FOREST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22fa803",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_evaluation(rf_model_reduced, reduced_X, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9747e95",
   "metadata": {},
   "source": [
    "## 6.6 Gradient Boosting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eae9398",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc834b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train a Gradient Boosting classifier\n",
    "GB_clf = GradientBoostingClassifier(random_state=42)\n",
    "GB_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2f0279",
   "metadata": {},
   "source": [
    "### EVALUATION OF GRADIENT BOOSTING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1349bc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluation(GB_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3060d210",
   "metadata": {},
   "source": [
    "## 6.7 XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cff1376",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# train an XGBoost classifier\n",
    "XGB_model = XGBClassifier(random_state=42)\n",
    "XGB_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2517a08c",
   "metadata": {},
   "source": [
    "### EVALUATION OF XGBOOST MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d2aae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluation(XGB_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3c62dd",
   "metadata": {},
   "source": [
    "# EXPORTING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd58dbd",
   "metadata": {},
   "source": [
    "# exporting preprocessed dataset to csv\n",
    "relative_path = \"../data/preprocessed\"\n",
    "\n",
    "if not os.path.exists(relative_path):\n",
    "    os.makedirs(relative_path)\n",
    "    \n",
    "X_train.to_csv(relative_path +'/train_dataset.csv', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
