{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "577ffc6b",
   "metadata": {},
   "source": [
    "# Credit score classification project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffdf52e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d679e489",
   "metadata": {},
   "source": [
    "# Train test split\n",
    "First of all we need to split our data into train, validation and test sets.\n",
    "\n",
    "Even though there is a test set given in the competition files, we don't have any access to the target variables, so we decided to use train.csv file only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9149ab5f",
   "metadata": {},
   "source": [
    "###### val. note: splitting into train, validation and test sets - good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1ad290b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv') # dataframe contains everything, not only train\n",
    "# test = pd.read_csv('test.csv') this one doesn't works - missing target value\n",
    "\n",
    "test_size = 0.2\n",
    "X = data.drop(columns=[\"Credit_Score\"]).copy()\n",
    "y = data[\"Credit_Score\"] # the target \n",
    "\n",
    "\n",
    "X_rem, X_test, y_rem, y_test = train_test_split(X,y, test_size=test_size, shuffle=False) \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_rem, y_rem, test_size=test_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15202eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged in order to perfrom preprocessing efficiently\n",
    "train = X_train.join(y_train)\n",
    "val = X_val.join(y_val)\n",
    "test = X_test.join(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10833d16",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4588\\1683379038.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/train.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/val.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/test.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3549\u001b[0m         )\n\u001b[0;32m   3550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3551\u001b[1;33m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[0;32m   3552\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3553\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1178\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m         )\n\u001b[1;32m-> 1180\u001b[1;33m         \u001b[0mcsv_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    239\u001b[0m         \"\"\"\n\u001b[0;32m    240\u001b[0m         \u001b[1;31m# apply compression and byte/text conversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m         with get_handle(\n\u001b[0m\u001b[0;32m    242\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[1;31m# Only for write methods\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;34m\"r\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_path\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 694\u001b[1;33m         \u001b[0mcheck_parent_directory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    695\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    566\u001b[0m     \u001b[0mparent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mparent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mrf\"Cannot save file into a non-existent directory: '{parent}'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'data'"
     ]
    }
   ],
   "source": [
    "train.to_csv(\"data/train.csv\")\n",
    "val.to_csv(\"data/val.csv\")\n",
    "test.to_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cda3922",
   "metadata": {},
   "source": [
    "###### val. note: checking whether distributions of respective values are equal or at least similar in both train and validation sets - good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892ed9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train[\"Credit_Score\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d92a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "val[\"Credit_Score\"].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f102f7",
   "metadata": {},
   "source": [
    "the variables are distributed similary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efc4e17",
   "metadata": {},
   "source": [
    "# Data Examination\n",
    "\n",
    "is placed in a different file in order to improve this file readability "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c77f97e",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e22ac8",
   "metadata": {},
   "source": [
    "First of all we git rid of columns that carry the same information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6422de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_columns(df):\n",
    "    df = df.drop([\"Name\", \"SSN\", \"ID\"], axis=\"columns\") # no added value, all the information in Customer_ID\n",
    "    df[\"Customer_ID\"] = df[\"Customer_ID\"].apply(lambda x: int(x[4:], 16)) # convert to int\n",
    "    \n",
    "    print(\"Columns containing id-like information preprocessed\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b15bc0",
   "metadata": {},
   "source": [
    "Here we literally 'clean' the data, removing unnecessary signs that appear randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787fd3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_numeric_data(col):\n",
    "    # some of the rows contain \"_\" sign\n",
    "    col.astype(str).replace(\"_\", \"\")\n",
    "    return pd.to_numeric(col, errors=\"coerce\") # errors='coerce', then invalid parsing will be set as NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746a2cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for cleaning numeric data where necessary\n",
    "def altering(df):\n",
    "    \n",
    "    columns_to_alter = ['Age', 'Annual_Income', 'Num_of_Loan','Num_of_Delayed_Payment',\n",
    "                        'Changed_Credit_Limit', 'Outstanding_Debt',\n",
    "                        'Amount_invested_monthly', 'Monthly_Balance']\n",
    "\n",
    "    df[columns_to_alter] = df[columns_to_alter].apply(clear_numeric_data, axis=1)\n",
    "\n",
    "    print(\"Numeric data preprocessed. Columns with numeric values contain numeric only variables. Changed columns types\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54dce4ef",
   "metadata": {},
   "source": [
    "Function below helps with removal outlying values from a column.\n",
    "If parameter (use_quantiles) is False, removes outliers outside given set range (a, b).\n",
    "Otherwise removes top 2 quantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c84e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_outliers(column, a=0, b=0.98, use_quantiles=True):\n",
    "    # function helps removing quantiles from a column, \n",
    "    # if parameter (use_quantiles) is False, removes outliers outside given range (a, b)\n",
    "    # otherwise removes top quantiles\n",
    "    \n",
    "    col = np.where(a < column, column, float('nan'))\n",
    "    if use_quantiles:\n",
    "        return np.where(col <= column.quantile(b), column, float('nan'))\n",
    "    return np.where(col <= b, column, float('nan'))\n",
    "\n",
    "\n",
    "def handle_outliers(df):\n",
    "    df[\"Age\"] = np.where((0 > df[\"Age\"]), -df[\"Age\"], df[\"Age\"]) # deleting weird outliers\n",
    "    df['Age'] = delete_outliers(df[\"Age\"], 0, 100, use_quantiles=False)\n",
    "    \n",
    "    df[\"Annual_Income\"] = delete_outliers(df[\"Annual_Income\"], 0, 0.99)\n",
    "    df[\"Num_Bank_Accounts\"] = delete_outliers(df[\"Num_Bank_Accounts\"])\n",
    "    df[\"Num_of_Loan\"] = delete_outliers(df[\"Num_of_Loan\"])\n",
    "    df[\"Interest_Rate\"] = delete_outliers(df[\"Interest_Rate\"])\n",
    "    df[\"Num_Credit_Card\"] = delete_outliers(df[\"Num_Credit_Card\"], 0, 0.97)\n",
    "    df[\"Num_of_Delayed_Payment\"] = delete_outliers(df[\"Num_of_Delayed_Payment\"])\n",
    "    df[\"Num_Credit_Inquiries\"] = delete_outliers(df[\"Num_Credit_Inquiries\"])\n",
    "    df[\"Total_EMI_per_month\"] = delete_outliers(df[\"Total_EMI_per_month\"], 0, 0.95)\n",
    "\n",
    "\n",
    "    print(\"Deleted outliers\")   \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98dfa837",
   "metadata": {},
   "source": [
    "## Encoding categorical data\n",
    "some variables contain categorical data - we want to save the unique values from them in order to apply one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6b4885",
   "metadata": {},
   "source": [
    "###### val. note: shouldn't code from next two cells be in pipeline function too? Since validation set can also contain such values as \"________\" and this code is not applied to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f55582",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Occupation\"] = np.where(train[\"Occupation\"] == \"_______\", \"Unknown\", train[\"Occupation\"])\n",
    "occupations_list = train[\"Occupation\"].unique()\n",
    "occupations_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9641a778",
   "metadata": {},
   "source": [
    "Sometimes when data is missing, it's possible to avail rows that pertain to the same customer and contain missing information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7200d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we fill the information for customers that have other rows with full information available\n",
    "train['Type_of_Loan'].fillna(train.groupby('Customer_ID')['Type_of_Loan'].first(), inplace=True)\n",
    "# later we fill with ''\n",
    "train['Type_of_Loan'].fillna('', inplace=True)\n",
    "    \n",
    "loan_types_list =  train['Type_of_Loan'].value_counts().head(9).index[1:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b585c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical(df):\n",
    "    # encode columns where necessary (Credit_Mix, Payment_of_Min_Amount, Credit_Score)\n",
    "    # mapping\n",
    "    credit_mix_dict = {'Bad':0, 'Standard':1, 'Good':2, '_':float('nan')}\n",
    "    poma_dict = {'No':0, 'Yes':1, 'NM':float('nan')}\n",
    "    credit_score_dict = {'Poor':0, 'Standard':1, 'Good':2}\n",
    "    month_dict = {\"January\": 1, \"February\": 2, \"March\": 3, \"April\": 4, \"May\": 5,\n",
    "                \"June\": 6, \"July\": 7, \"August\": 8}\n",
    "    \n",
    "    df['Payment_of_Min_Amount'] = df['Payment_of_Min_Amount'].map(poma_dict)\n",
    "    df['Credit_Mix'] = df['Credit_Mix'].map(credit_mix_dict)\n",
    "    df['Credit_Score'] = df['Credit_Score'].map(credit_score_dict) # this might be incorrect (?)\n",
    "    df[\"Month\"] = df[\"Month\"].map(month_dict)\n",
    "    \n",
    "    # Payment_Behaviour column brings two informations, one about spending, other about value payments\n",
    "    df[\"Payment_Behaviour\"] = df[\"Payment_Behaviour\"].replace('!@9#%8', 'Unknown_spent_Unknown_value_payments')\n",
    "    split_payment = lambda x:  ([x.split(\"_\")[0], x.split(\"_\")[2]] if (x is not None) else [\"Unknown\", \"Unknown\"])\n",
    "    df[\"Payment_Behaviour\"] = df[\"Payment_Behaviour\"].apply(split_payment)\n",
    "    df[[\"Spending_Behaviour\", \"Value_Payments\"]] = pd.DataFrame(df[\"Payment_Behaviour\"].tolist(), index=df.index)\n",
    "    \n",
    "    spending_dict = {'Low':0, 'High':1, 'Unknown':float('nan')}\n",
    "    value_dict = {'Small':0, 'Medium':1, 'Large':2,  'Unknown':float('nan')}\n",
    "    df['Spending_Behaviour'] = df['Spending_Behaviour'].map(spending_dict)\n",
    "    df['Value_Payments'] = df['Value_Payments'].map(value_dict)\n",
    "    \n",
    "    del df[\"Payment_Behaviour\"]\n",
    "    \n",
    "    \n",
    "    for loan_type in loan_types_list: # the single types of loans\n",
    "        df[loan_type] = df['Type_of_Loan'].str.contains(loan_type).astype(\"bool\")\n",
    "    del df[\"Type_of_Loan\"]\n",
    "    \n",
    "    \n",
    "    # credit history age    \n",
    "    df['Credit_History_Age'] = df['Credit_History_Age'].apply(history_age)\n",
    "    \n",
    "    # Occupation - ____ for uneployed\n",
    "    df[\"Occupation\"] = np.where(df[\"Occupation\"] == \"_______\", \"Unknown\", df[\"Occupation\"])\n",
    "    df[\"Occupation\"] = np.where(df[\"Occupation\"].isin(occupations_list), df[\"Occupation\"], \"Unknown\") # to handle different occupations in test data\n",
    "    df = df.join(pd.get_dummies(df['Occupation']))\n",
    "    del df[\"Occupation\"]\n",
    "\n",
    "    print(\"Categorical columns with string values encoded. Added new columns where necessary (one-hot encoding)\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1993b7",
   "metadata": {},
   "source": [
    "## handling NaNs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268925b9",
   "metadata": {},
   "source": [
    "We will impute missing data. In case of some values we look up to rows containing\n",
    "data about the same customer, using mode/median of values pertaining to him. If for customer\n",
    "there are no other rows, we impute using globally most common values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef5189e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_values(df):\n",
    "    \n",
    "    continuous_values = ['Monthly_Inhand_Salary', 'Amount_invested_monthly',\n",
    "                         'Monthly_Balance', 'Credit_History_Age', \"Outstanding_Debt\",\n",
    "                         \"Changed_Credit_Limit\", \"Annual_Income\"]\n",
    "    \n",
    "    for column in continuous_values:\n",
    "        df[column] = df[column].fillna(df.groupby('Customer_ID')[column].transform(\"mean\"))\n",
    "    # using mean is not causing any trouble here, we're practically taking the value that appears\n",
    "    # in the rows with the same id\n",
    "        \n",
    "    \n",
    "    discrete_columns = [\"Age\", \"Num_Credit_Inquiries\", \"Num_of_Loan\", \"Credit_Mix\",\n",
    "                        \"Num_of_Delayed_Payment\", \"Num_Credit_Inquiries\", \n",
    "                        \"Spending_Behaviour\", \"Payment_of_Min_Amount\", \"Value_Payments\"]\n",
    "    # for discrete values we'll impute nans with mode\n",
    "    for column in discrete_columns:\n",
    "        #train[column].fillna(train.groupby('Customer_ID')[column].agg(lambda x: pd.Series.mode(x)[0]), inplace=True) \n",
    "        df[column].fillna(df.groupby('Customer_ID')[column].transform('median'), inplace=True) \n",
    "        pass\n",
    "    \n",
    "    df = df.fillna(df.median()) # in case a customer doesn't have any entries\n",
    "\n",
    "\n",
    "    print(\"NA values imputed within numeric columns\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a172a4",
   "metadata": {},
   "source": [
    "###### val. note: not like it matters, but it would be easier to read if this function was directly below cell that uses this function (i.e. one cell above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786b3233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing Credit_History_Age so that's continuous\n",
    "import re\n",
    "def history_age(age):\n",
    "    try : \n",
    "        years = int(re.findall('[0-9]+', age)[0])\n",
    "        month = int(re.findall('[0-9]+', age)[1])\n",
    "        return years*12 + month\n",
    "    except :\n",
    "        return np.nan\n",
    "    \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc32c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_discrete_string(df):\n",
    "\n",
    "    discrete_string_columns = [\"Occupation\", \"Type_of_Loan\", \"Payment_Behaviour\"]\n",
    "    # fill missing data in columns that are strings\n",
    "\n",
    "    for column in discrete_string_columns:\n",
    "        most_common_globally = df[column].agg(lambda x: pd.Series.mode(x)[0])\n",
    "        df[column].fillna(df.groupby('Customer_ID')[column].agg(\n",
    "            lambda x: (most_common_globally if len(pd.Series.mode(x)) == 0 else pd.Series.mode(x)[0])\n",
    "            ), inplace=True) \n",
    "        \n",
    "\n",
    "    print(\"NA values imputed within text columns\")\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225352d5",
   "metadata": {},
   "source": [
    "## Pipeline\n",
    "\n",
    "to faciliate the data preprocessing process we used pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e846699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "drop_transformer = FunctionTransformer(id_columns)\n",
    "altering_transformer = FunctionTransformer(altering)\n",
    "outlier_transformer = FunctionTransformer(handle_outliers)\n",
    "categorical_transformer = FunctionTransformer(encode_categorical)\n",
    "imputer_transformer = FunctionTransformer(impute_values)\n",
    "discrete_imputer_transformer = FunctionTransformer(impute_discrete_string)\n",
    "\n",
    "# all the afore declared processings applied\n",
    "prepipe = Pipeline([\n",
    "    (\"drop\", drop_transformer),\n",
    "    (\"altering\", altering_transformer),\n",
    "    (\"outliers\", outlier_transformer),\n",
    "    (\"impute_discrete_string\", discrete_imputer_transformer),\n",
    "    (\"categorical\", categorical_transformer),\n",
    "    (\"impute\", imputer_transformer)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402b1b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = prepipe.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddc1fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify the pipe transformation\n",
    "described = train.describe()\n",
    "described"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bcfc9d",
   "metadata": {},
   "source": [
    "###### val. note: personally for me it is OK. But during our presentation lecturer was not very satisfied seeing so many histograms..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a53f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_plot = train.hist(figsize=(30, 20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e10bf4",
   "metadata": {},
   "source": [
    "###### val. note: very fine correlation matrix - good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2ea1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(train.corr(), cmap=\"YlGnBu\") # correlation map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fb2f07",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f917687",
   "metadata": {},
   "source": [
    "We will initially create the models, to check which features have the highest importance.\n",
    "Our intention is to drop the irrelevant later after the 1st model fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd12554",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fee98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training dataset\n",
    "y = train['Credit_Score']\n",
    "del train['Credit_Score']\n",
    "y_train = y\n",
    "X_train = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2869f728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation dataset\n",
    "val = prepipe.transform(val)\n",
    "X_val = val\n",
    "y_val = val[\"Credit_Score\"]\n",
    "del X_val[\"Credit_Score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef049a4",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f879fc81",
   "metadata": {},
   "source": [
    "1st fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174eb5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce53215",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=120)\n",
    "rf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ec79ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c955f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_pred, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f55f76d",
   "metadata": {},
   "source": [
    "# Verify feature importance in random forest model\n",
    "\n",
    "Our goal is to select the most predictive variables, as the credit score prediction has to be explainable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07266953",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(rf_model.feature_importances_,\n",
    "                                   X_val.columns,\n",
    "                                   columns=['Importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d472b887",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_sorted = feature_importances.sort_values(by='Importance', ascending=False).head(20)\n",
    "\n",
    "plt.title('Feature Importances')\n",
    "\n",
    "plt.barh(feature_importance_sorted.index, feature_importance_sorted[\"Importance\"])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cec251",
   "metadata": {},
   "source": [
    "###### val. note: idk if it is only my problem but this cell raise error (sth wrong with y_val)\n",
    "ValueError: At least one label specified must be in y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b841c79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "class_names = ['Poor', 'Standard', 'Good']\n",
    "cm = confusion_matrix(y_val, y_pred, labels=class_names)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
    "disp.plot(cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcadb951",
   "metadata": {},
   "source": [
    "# shapley examination\n",
    "\n",
    "A handy library `shap` comes to rescue - it provides some robust tools that helps explaining the model's behaviour."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8243e1c9",
   "metadata": {},
   "source": [
    "###### val. note: It would be more helpful if you described shap library more, at least what used functions do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14b334b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs() # this code should execute within 5 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308479db",
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(rf_model)\n",
    "shap_values = explainer.shap_values(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1d1bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_train.loc[1:100, :].values, plot_type=\"bar\", class_names= class_names, feature_names = X_train.loc[1:100, :].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80d9575",
   "metadata": {},
   "source": [
    "in the example above we can see for instance that model doesn't use much information from feature 'Credit_Mix' when it comes to predicting label 'Standard'\n",
    "\n",
    "below we can see plot showing the importance of features while predicting label 'Poor' - value 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385d3fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[0], X_train.loc[1:100, :].values, feature_names = X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78caa36",
   "metadata": {},
   "source": [
    "As it turns out the most important variable is `Credit Mix`, which refers to the types of different credit accounts you have – mortgages, loans, credit cards, etc. It is a kind of assessment of the current credit that the bank sets before signing the contract for new services.\n",
    "\n",
    "Credit Mix can be easily improved by paying installments on time, setting up a credit card for a small amount and maintaining it regularly, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a039c868",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.dependence_plot(0, shap_values[2], X_train.loc[1:100, :].values, feature_names=X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84280d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single observation\n",
    "\n",
    "row=70\n",
    "shap.force_plot(explainer.expected_value[0], shap_values[0][row], X_train.loc[1:100, :].values[row], feature_names = X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb77e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcd7546",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shap.waterfall_plot(shap.Explanation(values=shap_values[1][row], \n",
    "                                              base_values=explainer.expected_value[0], data=X_train.iloc[row],  \n",
    "                                         feature_names=X_train.columns.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b49219",
   "metadata": {},
   "source": [
    "it looks like if the credit mix is higher, there is greater chance that model will clasify the observation with better category "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2bdeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = X_train[[\"Credit_Mix\"]].join(y_train).groupby([\"Credit_Mix\", \"Credit_Score\"]).agg(count=('Credit_Score', 'count')).reset_index()\n",
    "df = df.pivot(index=\"Credit_Mix\", columns=\"Credit_Score\", values=\"count\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f794a3c",
   "metadata": {},
   "source": [
    "# Dropping highly correlated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045fa326",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_delete = []\n",
    "for i in range(len(X_train.columns)):\n",
    "    for j in range(i+1, len(X_train.columns)):\n",
    "        # we iterate over every pair of columns\n",
    "        # if the correlation between them is over 0.5 we eliminate the less predictive (for our particular model) column\n",
    "        if (abs(X_train[X_train.columns[i]].corr(X_train[X_train.columns[j]])) > 0.7):\n",
    "            if feature_importances.loc[X_train.columns[i]][0] < feature_importances.loc[X_train.columns[j]][0]:\n",
    "                columns_to_delete.append(feature_importances.loc[X_train.columns[i]].name)\n",
    "            else:\n",
    "                columns_to_delete.append(feature_importances.loc[X_train.columns[j]].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef46246",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_delete.append('Customer_ID')\n",
    "columns_to_delete = list(set(columns_to_delete)) # get unique values\n",
    "columns_to_delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4adf015",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2 = X_train.drop(columns_to_delete, axis=1)\n",
    "X_val_2 = X_val.drop(columns_to_delete, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e63ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_2 = feature_importances.loc[feature_importances.index.isin(X_train_2)].sort_values(by='Importance', ascending=False)\n",
    "feature_importances_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057baca4",
   "metadata": {},
   "source": [
    "# New model, trained without highly correlated columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ed2f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_2 = RandomForestClassifier(n_estimators=100)\n",
    "rf_model_2.fit(X_train_2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46a2f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_2 = rf_model_2.predict(X_val_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e1c366",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_pred_2, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5067d2b",
   "metadata": {},
   "source": [
    "# XGBoost attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0af7bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import (\n",
    "    BaggingClassifier,\n",
    "    ExtraTreesClassifier,\n",
    "    RandomForestClassifier,\n",
    "    StackingClassifier,\n",
    "    HistGradientBoostingClassifier\n",
    ")\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37fb9cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gbc_model= GradientBoostingClassifier()\n",
    "gbc_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efad3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_xgboost = gbc_model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2dfadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_pred_xgboost, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b9f6b2",
   "metadata": {},
   "source": [
    "XGBoost Classifier hasn't turned out to be much better than the Random Forest Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe020c59",
   "metadata": {},
   "source": [
    "# Stacked Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdb97be",
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging = BaggingClassifier(n_jobs=-1)\n",
    "extraTrees = ExtraTreesClassifier(max_depth=10, n_jobs=-1)\n",
    "randomForest = RandomForestClassifier(n_jobs=-1)\n",
    "histGradientBoosting = HistGradientBoostingClassifier()\n",
    "XGB = XGBClassifier(n_jobs=-1)\n",
    "\n",
    "model = StackingClassifier([\n",
    "    ('bagging', bagging),\n",
    "    ('extraTress', extraTrees),\n",
    "    ('randomforest', randomForest),\n",
    "    ('histGradientBoosting', histGradientBoosting),\n",
    "    ('XGB', XGB)\n",
    "], n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9c0bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7acd372",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_val)\n",
    "print(classification_report(y_pred,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84bd0df",
   "metadata": {},
   "source": [
    "although we tried to choose the best model using many different types of models, each of them proved to be very similarly effective"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b4971f",
   "metadata": {},
   "source": [
    "# Attempt to drop irrelevant features with SelectKBest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f55a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "#from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b4da5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestfeatures = SelectKBest(k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc67fafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit = bestfeatures.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a9dfc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fit.scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df799b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "featureScores = pd.DataFrame(fit.scores_, X_train.columns,  columns=['Importance_Score'])\n",
    "featureScores = featureScores.sort_values(by='Importance_Score', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea81207",
   "metadata": {},
   "outputs": [],
   "source": [
    "featureScores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37451be9",
   "metadata": {},
   "source": [
    "# New model without features with less importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb604af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_3 = X_train[featureScores.index]\n",
    "X_val_3 = X_val[featureScores.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1c7412",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_3, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fae647",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_val_3)\n",
    "print(classification_report(y_pred,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfaa9ee",
   "metadata": {},
   "source": [
    "selecting columns in different ways did not bring the expected result - models trained on fewer columns did not perform better, although they can be better explained. \n",
    "We become convinced that the most predictive variables are `Credit_Mix`, `Interest_Rate`, `Payment_of_Min_Amount` and other columns describing the credit cards usage or variables describing whether payments were made on time. Features chosen by the model are explainable and its behaviour is explainable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54ff3b6",
   "metadata": {},
   "source": [
    "# lazy predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7c131e",
   "metadata": {},
   "source": [
    "###### val. note: This is very cool way to try out different models, haven't seen before, so cool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1dfa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lazypredict.Supervised import LazyClassifier\n",
    "\n",
    "clf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\n",
    "models,predictions = clf.fit(X_train, X_val, y_train, y_val)\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bfdbae",
   "metadata": {},
   "source": [
    "# Hiperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009dad32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360b35b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Parameters currently in use:\\n')\n",
    "print(rf_model.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1f6b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = [i for i in range (5,20,3)]\n",
    "scores = []\n",
    "\n",
    "for k in k_values:\n",
    "    rf = RandomForestClassifier(max_depth=k)\n",
    "    score = cross_val_score(rf, X_train, y, cv=5)\n",
    "    scores.append(np.mean(score))\n",
    "    print(f\"{k} job done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ce286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(x = k_values, y = scores, marker = 'o')\n",
    "plt.xlabel(\"max depth\")\n",
    "plt.ylabel(\"Accuracy Score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77e97aa",
   "metadata": {},
   "source": [
    "it looks like the best accuracy results are for models with parameter `max_depth` around 13."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9086ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4c0d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores - it takes a lot of time btw\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c16e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [15, 30, 50, 100],\n",
    "    'max_features': [3, 4],\n",
    "    'min_samples_leaf': [2, 3, 4],\n",
    "    'min_samples_split': [10, 12],\n",
    "    'n_estimators': [500, 1000, 2000]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 2, n_jobs = -1, verbose = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcbf298",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4734632d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "filename = \"saved_models/rf_grid_2.sav\" # save the model for later - unfortunately the file is too big to send it over\n",
    "pickle.dump(grid_search.best_estimator_, open(filename, 'wb'))\n",
    "grid_search.best_params_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9feb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce39a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf_model.predict(X_val)\n",
    "print(classification_report(y_pred,y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e606a65c",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "During the first project in the subject Introduction to Machine Learning, we created a classifying model predicting a **Credit Score** value for different clients, based on some data about them. \n",
    "\n",
    "After thorough data exploration we prepared a preprocessing pipeline that was handling the missing data, incorrect data formatting, outliers. Then, the cleaned data could be used to train different models and evaluate their performance with different grades. \n",
    "\n",
    "We also made a feature selection and investigated the model's choices, since its behaviour should be explainable by the problem it solves.\n",
    "\n",
    "After testing different types and models and tuning their hyperparameters, we choose one model - **Random Forest Classifier** that has been saved to a file for later evalution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101fc667",
   "metadata": {},
   "source": [
    "###### val. note: This is preprocessing and machine learning done right and very carefully. From our side as validation team there were no actual errors found thus no negative remarks can be concluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6101db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
